{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from difflib import SequenceMatcher as seq_matcher\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_metric(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scorer = make_scorer(eval_metric, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pattern to remove stopwords\n",
    "pattern = re.compile(r'\\b(' + r'|'.join(text.ENGLISH_STOP_WORDS) + r')\\b\\s*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate porter stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric: RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load train and test set\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_expansion(train, test, y, top_words=10):\n",
    "    queries_ext_train = np.zeros(len(train)).astype(np.object)\n",
    "    queries_ext_test = np.zeros(len(test)).astype(np.object)\n",
    "\n",
    "    queries = train.search_term\n",
    "    queries_test = test.search_term\n",
    "    \n",
    "    titles = train.product_title\n",
    "    titles_test = test.product_title\n",
    "    \n",
    "    for q in np.unique(queries):\n",
    "        q_mask = (queries == q).values\n",
    "        q_test = (queries_test == q).values\n",
    "\n",
    "        titles_q = titles[q_mask]\n",
    "        y_q = y[q_mask]\n",
    "\n",
    "        good_mask = (y_q > 2.).values\n",
    "        titles_good = titles_q[good_mask]\n",
    "\n",
    "        ext_q = str(q)\n",
    "\n",
    "        for item in titles_good:\n",
    "            ext_q += ' ' + str(item)\n",
    "        \n",
    "        ext_q = pattern.sub('', ext_q)\n",
    "        c = [word for word, it in Counter(ext_q.split()).most_common(top_words)]\n",
    "        c = ' '.join(c)\n",
    "\n",
    "        queries_ext_train[q_mask] = c\n",
    "        queries_ext_test[q_test] = c\n",
    "    \n",
    "    return queries_ext_train, queries_ext_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. Preprocessing ( Sanitize strings, correct spelling mistakes )\n",
    "2. Stemming ( Check to see if this helps )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_characters(char):\n",
    "    return char == '\\n' or 32 <= ord(char) <= 126\n",
    "\n",
    "def sanitize(s):\n",
    "    s = s.replace('ft.', 'feet')\n",
    "    s = s.replace('cu.', 'cubic')\n",
    "    s = s.replace('mm', 'milimeters')\n",
    "    s = s.replace('oz.', 'ounces')\n",
    "    s = s.replace('btu', 'british thermal unit')\n",
    "    s = s.replace('otr', 'over the range')\n",
    "    s = s.replace('lb.', 'pounds')\n",
    "    s = s.replace('in.', 'inches')\n",
    "    s = s.replace('&amp;', 'and')\n",
    "    s = s.replace('sq.', 'square')\n",
    "    s = s.replace('gal.', 'gallon')\n",
    "    \n",
    "    return s\n",
    "\n",
    "def preprocess(s):\n",
    "    s = filter(filter_characters, s)\n",
    "    s = s.lower()\n",
    "    s = sanitize(s)\n",
    "    \n",
    "    return pattern.sub('', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_set(x):\n",
    "    x = x.lower() # lowecase string\n",
    "    x = x.split(' ') # split on empty space will work on clever ways to do this later\n",
    "    return set(x)\n",
    "\n",
    "def Dice(row):\n",
    "    product_title = row['product_title']\n",
    "    search_term = row['search_term']\n",
    "    \n",
    "    product_title = create_set(product_title)\n",
    "    search_term = create_set(search_term)\n",
    "\n",
    "    return (2 * len(product_title & search_term)) / (len(product_title) + len(search_term))\n",
    "\n",
    "def Jaccard(row):\n",
    "    product_title = row['product_title']\n",
    "    search_term = row['search_term']\n",
    "    \n",
    "    product_title = create_set(product_title)\n",
    "    search_term = create_set(search_term)\n",
    "    \n",
    "    return len(product_title & search_term) / len(product_title | search_term)\n",
    "\n",
    "def Overlap(row):\n",
    "    product_title = row['product_title']\n",
    "    search_term = row['search_term']\n",
    "    \n",
    "    product_title = create_set(product_title)\n",
    "    search_term = create_set(search_term)\n",
    "    \n",
    "    return len(product_title & search_term) / min(len(product_title), len(search_term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_words_in_query(query):\n",
    "    return len(query.split())\n",
    "\n",
    "def num_words_in_title(title):\n",
    "    return len(title.split())\n",
    "\n",
    "def query_title_overlap(row):\n",
    "    query = row['search_term']\n",
    "    title = row['product_title']\n",
    "    query_words = query.split()\n",
    "    \n",
    "    count_overlap = 0\n",
    "    for word in query_words:\n",
    "        if query in title:\n",
    "            count_overlap += 1\n",
    "    \n",
    "    return count_overlap\n",
    "\n",
    "def levenshtein_distance(row):\n",
    "    query = row['search_term']\n",
    "    title = row['product_title']\n",
    "    \n",
    "    return 1 - seq_matcher(None, query, title).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model Based on Average Dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[['product_title', 'search_term']]\n",
    "y = train.relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.loc[:, 'product_title'] = X.product_title.map(preprocess)\n",
    "X.loc[:, 'search_term'] = X.search_term.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.loc[:, 'product_title'] = test.product_title.map(preprocess)\n",
    "test.loc[:, 'search_term'] = test.search_term.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## calculate average dice score\n",
    "X.loc[:, 'dice_score'] = X.apply(Dice, axis=1)\n",
    "test.loc[:, 'dice_score'] = test.apply(Dice, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## calculate jaccard distance\n",
    "X.loc[:, 'jaccard_distance'] = X.apply(Jaccard, axis=1)\n",
    "test.loc[:, 'jaccard_distance'] = test.apply(Jaccard, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## calculate overlap\n",
    "X.loc[:, 'overlap'] = X.apply(Overlap, axis=1)\n",
    "test.loc[:, 'overlap'] = test.apply(Overlap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## features\n",
    "X.loc[:, 'num_words_in_query'] = X.search_term.map(num_words_in_query)\n",
    "X.loc[:, 'num_words_in_title'] = X.product_title.map(num_words_in_title)\n",
    "X.loc[:, 'query_title_overlap'] = X.apply(query_title_overlap, axis=1)\n",
    "X.loc[:, 'one-edit-distance'] = X.apply(levenshtein_distance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1279)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['dice_score', 'jaccard_distance', 'overlap', 'num_words_in_query', \\\n",
    "            'num_words_in_title', 'query_title_overlap', 'one-edit-distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "etr = ExtraTreesRegressor(n_estimators=500, max_depth=7, min_samples_leaf=3, n_jobs=-1)\n",
    "rf = RandomForestRegressor(n_estimators=250, max_depth=10, min_samples_leaf=3, min_samples_split=3, n_jobs=-1)\n",
    "gbr = GradientBoostingRegressor()\n",
    "xgbr = XGBRegressor(n_estimators=100, learning_rate=0.3, subsample=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "scores = cross_val_score(xgbr, X_train[features], y_train, scoring=rmse_scorer, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score -0.495223 and standard deviation 0.003914 \n"
     ]
    }
   ],
   "source": [
    "print 'Average score %f and standard deviation %f ' %(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.3, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr.fit(X_train[features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_preds = xgbr.predict(X_train[features])\n",
    "test_preds = xgbr.predict(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set 0.489262 \n",
      "RMSE on test set 0.493011 \n"
     ]
    }
   ],
   "source": [
    "print 'RMSE on training set %f ' %(eval_metric(y_train, train_preds))\n",
    "print 'RMSE on test set %f ' %(eval_metric(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X[['dice_score']], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(test[['dice_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cap_predictions(pred):\n",
    "    if pred > 3.0:\n",
    "        return 3.0\n",
    "    elif pred < 1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return pred\n",
    "predictions = map(cap_predictions, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submissions = pd.read_csv('../data/sample_submission.csv')\n",
    "submissions.loc[:, 'relevance'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions.to_csv('../submissions/linear_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_corpus = X_train.apply(lambda x: '%s %s' %(x['search_term'], x['product_title']), axis=1)\n",
    "test_corpus = X_test.apply(lambda x: '%s %s' %(x['search_term'], x['product_title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vec = text.CountVectorizer(max_df=.95, min_df=3)\n",
    "train_corpus = count_vec.fit_transform(train_corpus)\n",
    "test_corpus = count_vec.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(train_corpus, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_preds = clf.predict(train_corpus)\n",
    "test_preds = clf.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set 0.419057 \n",
      "RMSE on test set 0.533445 \n"
     ]
    }
   ],
   "source": [
    "print 'RMSE on training set %f ' %(eval_metric(y_train, train_preds))\n",
    "print 'RMSE on test set %f ' %(eval_metric(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_corpus = X_train.apply(lambda x: '%s %s' %(x['search_term'], x['product_title']), axis=1)\n",
    "test_corpus = X_test.apply(lambda x: '%s %s' %(x['search_term'], x['product_title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vec = text.TfidfVectorizer(max_df=.95, min_df=3)\n",
    "train_corpus = tfidf_vec.fit_transform(train_corpus)\n",
    "test_corpus = tfidf_vec.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(train_corpus, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = clf.predict(train_corpus)\n",
    "test_preds = clf.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set 0.418427 \n",
      "RMSE on test set 0.534408 \n"
     ]
    }
   ],
   "source": [
    "print 'RMSE on training set %f ' %(eval_metric(y_train, train_preds))\n",
    "print 'RMSE on test set %f ' %(eval_metric(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expanded_query_train, expanded_query_test = query_expansion(train, test, train.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'query'] = expanded_query_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[['product_title', 'query']]\n",
    "y = train.relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.loc[:, 'product_title'] = X.product_title.map(preprocess)\n",
    "X.loc[:, 'query'] = X['query'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_corpus = X_train.apply(lambda x: '%s %s' %(x['query'], x['product_title']), axis=1)\n",
    "test_corpus = X_test.apply(lambda x: '%s %s' %(x['query'], x['product_title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vec = text.TfidfVectorizer(max_df=.95, min_df=3)\n",
    "train_corpus = tfidf_vec.fit_transform(train_corpus)\n",
    "test_corpus = tfidf_vec.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(train_corpus, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = clf.predict(train_corpus)\n",
    "test_preds = clf.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set 0.413295 \n",
      "RMSE on test set 0.555150 \n"
     ]
    }
   ],
   "source": [
    "print 'RMSE on training set %f ' %(eval_metric(y_train, train_preds))\n",
    "print 'RMSE on test set %f ' %(eval_metric(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
